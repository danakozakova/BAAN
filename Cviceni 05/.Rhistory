library(ggplot2)
txhousing
#alebo
ggplot::txhousing
#alebo
ggplot2::txhousing
# alebo natiahnut do environment
data("txhousing", package = "ggplot2")
txhousing |> class()
txhousing |> head()
### UKOL 1 ###
# Načtěte data z binárního R formátu. Soubor se jmenuje “tec00001.RData”. Obsahuje tabulku tec00001.
load(“tec00001.RData”)
### UKOL 1 ###
# Načtěte data z binárního R formátu. Soubor se jmenuje “tec00001.RData”. Obsahuje tabulku tec00001.
load('tec00001.RData')
setwd("~/Aved/Cv05")
### UKOL 1 ###
# Načtěte data z binárního R formátu. Soubor se jmenuje “tec00001.RData”. Obsahuje tabulku tec00001.
load('tec00001.RData')
### UKOL 2 ###
# Načtěte stejnou tabulku ze souboru “tec00001.csv”. Tabulku pojmenujte tec00001csv.
library(readr)
library(readr)
tec00001 <- read_csv("tec00001.csv", col_types = cols(time = col_date(format = "%Y-/%m-/%d")))
tec00001 <- read_csv("tec00001.csv", col_types = cols(time = col_date(format = "%Y-/%m-/%d")))
View(tec00001)
tec00001 <- read_csv("tec00001.csv",
col_types = cols(
na_item = col_character(),
unit = col_character(),
geo = col_character(),
time = col_date(format = "%Y-%m-%d"),
values = col_double()
))
tec00001
library(readr)
tec00001_tsv <- read_csv("tec00001.tsv.gz")
View(tec00001_tsv)
tec00001tsv <- read_tsv(
"tec00001.tsv.gz",
col_types = "cnnnnnnnnnnnn",
na = ":"
)
### UKOL 3 ###
# Načtěte stejnou tabulku ze souboru “tec00001.tsv.gz”. Tabulku pojmenujte tec00001tsv.
# Jak se tato tabulka liší od tabulky tec00001csv? (Tento soubor je přímo stažený z Eurostatu.)
tec00001tsv <- read_csv("tec00001.tsv.gz")
tec00001tsv
### UKOL 3 ###
# Načtěte stejnou tabulku ze souboru “tec00001.tsv.gz”. Tabulku pojmenujte tec00001tsv.
# Jak se tato tabulka liší od tabulky tec00001csv? (Tento soubor je přímo stažený z Eurostatu.)
## toto načíta defaultne, ale zle
tec00001tsv <- read_csv("tec00001.tsv.gz")
tec00001tsv
## toto mi správne načíta
tec00001tsv <- read_tsv(
"tec00001.tsv.gz",
col_types = "cnnnnnnnnnnnn",
na = ":"
)
tec00001tsv
library(readr)
tec00001_tsv <- read_delim("tec00001.tsv.gz",
delim = "\t", escape_double = FALSE,
col_types = cols(`2007` = col_number()),
trim_ws = TRUE)
tec00001_tsv <- read_delim("tec00001.tsv.gz",
delim = "\t", escape_double = FALSE,
col_types = cols(`2007` = col_number()),
trim_ws = TRUE)
problems(dat)
problems(tec00001_tsv)
# CEZ dialog okno
tec00001tsv <- read_delim("tec00001.tsv.gz",
delim = "\t", escape_double = FALSE,
col_types = cols(`2007` = col_number()),
trim_ws = TRUE)
tec00001tsv <- read_tsv("tec00001.tsv.gz",
col_types = cols(.default = col_character()),
na = ':')
tec00001xls <- read_excel(filename)
filename <- "Eurostat_Table_tec00001FlagDesc_11c465e3-eae1-4c8e-b956-f473d4a78a0a.xls"
tec00001xls <- read_excel(filename)
tec00001xls <- read_excel(filename)
library(readxl)
filename <- "Eurostat_Table_tec00001FlagDesc_11c465e3-eae1-4c8e-b956-f473d4a78a0a.xls"
tec00001xls <- read_excel(filename)
tec00001xls <- read_excel(filename,
range = "A4:Y47")
# Týden 5: Načítání dat do R
# https://is.muni.cz/auth/el/econ/podzim2025/MPE_AVED/um/exercises/ex05.html
rm(list = ls())
tec00001xls <- read_excel(filename,
range = "A4:Y47")
library(readxl)
filename <- "Eurostat_Table_tec00001FlagDesc_11c465e3-eae1-4c8e-b956-f473d4a78a0a.xls"
tec00001xls <- read_excel(filename,
range = "A4:Y47")
View(tec00001xls)
tec00001xls <- read_excel(filename,
range = "A4:Y47", na = ":")
tec00001xls <- read_excel(filename,
range = "A4:Y47", na = ":",
col_types = c("text", rep(c("numeric", "skip"), 12)))
# to iste, ale zachovame poznámky
# len zmeneny skip na text
tec00001xls <- read_excel("exdata05/Eurostat_Table_tec00001FlagDesc_11c465e3-eae1-4c8e-b956-f473d4a78a0a.xls",
range = "A4:Y47", na = ":",
col_types = c("text", rep(c("numeric", "text"), 12))) # text, rok(cislo), vyhod, rok(cislo), vyhod, ....
### Poznámka 1 ###
# nacitanie priamo z Eurostat
tec00001 <- eurostat::get_eurostat("tec00001")
### Poznámka 1 ###
# nacitanie priamo z Eurostat
install.packages("eurostat")
tec00001 <- eurostat::get_eurostat("tec00001")
### Poznámka 1 ###
# nacitanie priamo z Eurostat
# install.packages("eurostat")
tec00001 <- eurostat::get_eurostat("tec00001")
tec00001
rm(list = ls())
#############################################################################
# Murphy: Co se může pokazit…
#############################################################################
### UKOL 1 ###
read_csv("experiment.xls")
#############################################################################
# Murphy: Co se může pokazit…
#############################################################################
### UKOL 1 ###
read_csv("experiment.csv")
readLines(filename)
#############################################################################
# Murphy: Co se může pokazit…
#############################################################################
### UKOL 1 ###
filename <- "experiment.csv"
read_csv(filename)
problems(filename)
problems(filename)
read_csv(filename)
problems(filename)
read_lines(filename)
read_lines(filename) |> head(15)
read_lines(filename) |> head(15) |> cat(sep = "\n")
library(readr)
experiment <- read_delim("experiment.csv",
delim = ":", escape_double = FALSE, col_types = cols(id = col_integer(),
height = col_integer(), weight = col_integer(),
treatment = col_factor(levels = c("control",
"group A", "group B"))), locale = locale(decimal_mark = ",",
grouping_mark = "."), trim_ws = TRUE,
skip = 8)
experiment <- read_delim("experiment.csv",
delim = ":", escape_double = FALSE, col_types = cols(id = col_integer(),
height = col_integer(), weight = col_integer(),
treatment = col_factor(levels = c("control",
"group A", "group B"))), locale = locale(decimal_mark = ",",
grouping_mark = "."), trim_ws = TRUE,
skip = 8)
experiment
library(readr)
experiment2 <- read_delim("experiment2.csv",
delim = ":", escape_double = FALSE, col_names = FALSE,
col_types = cols(`1` = col_integer(),
X1 = col_integer(), X5 = col_factor(levels = c("control",
"group A", "group B"))), trim_ws = TRUE)
colnames(experiment2)
colnames(experiment2) <- c("id", "name", "height", "weight",
"treatment", "value")
experiment2
experiment2 <- read_delim("experiment2.csv",
delim = ":", escape_double = FALSE, col_names = FALSE,
col_names = c("id", "name", "height", "weight", "treatment", "value"),
col_types = cols(id = col_integer(),
name = col_character(),
height = col_integer(),
weight = col_integer(),
treatment = col_factor(levels = c("control",
"group A",
"group B")),
value = col_double()),
locale = locale(decimal_mark = ","))
experiment2 <- read_delim("experiment2.csv",
delim = ":", escape_double = FALSE,
col_names = c("id", "name", "height", "weight", "treatment", "value"),
col_types = cols(id = col_integer(),
name = col_character(),
height = col_integer(),
weight = col_integer(),
treatment = col_factor(levels = c("control",
"group A",
"group B")),
value = col_double()),
locale = locale(decimal_mark = ","))
experiment2
# Clear variables and console
rm(list = ls())
cat("\014")
# Load packages
library(tidyverse)
library(janitor)
library(rstan)
library(bayesplot)
# (a)
# Step 1: Define a grid of lambda values
grid_data  <- data.frame(
lambda_grid = seq(from = 0, to = 8, length = 501))
grid_data
grid_data |> head()
View(grid_data)
# Step 2: Evaluate the prior & likelihood at each lambda
grid_data <- grid_data %>%
mutate(prior = dgamma(lambda_grid, 20, 5),
likelihood = dpois(0,lambda_grid) * dpois(1,lambda_grid) * dpois(0,lambda_grid))
View(grid_data)
# Step 3: Approximate the posterior
grid_data <- grid_data %>%
mutate(unnormalized = likelihood*prior,
posterior = unnormalized/sum(unnormalized))
ggplot(grid_data, aes(x = lambda_grid, y = posterior)) +
geom_point() +
geom_segment(aes(x = lambda_grid, xend = lambda_grid, y = 0, yend = posterior))
ggplot(grid_data, aes(x = lambda_grid, y = posterior)) +
geom_point()
ggplot(grid_data, aes(x = lambda_grid, y = posterior)) +
geom_point() +
geom_segment(aes(x = lambda_grid, xend = lambda_grid, y = 0, yend = posterior))
ggplot(grid_data, aes(x = lambda_grid, y = posterior)) +
geom_point()
post_sample <- sample_n(grid_data, size = 10000,
weight = posterior, replace = TRUE)
View(post_sample)
ggplot(post_sample, aes(x = lambda_grid)) +
geom_histogram(aes(y = after_stat(density)), colour = "white", binwidth = 0.1) +
stat_function(fun = dgamma, args = list(20+1, 5+3)) +
lims(x = c(0, 10))
?after_stat
# Step 4: sample from the discretized posterior
post_sample <- sample_n(grid_data, size = 10000,
weight = posterior, replace = TRUE)
ggplot(grid_data, aes(x = lambda_grid, y = posterior)) +
geom_point() +
geom_segment(aes(x = lambda_grid, xend = lambda_grid, y = 0, yend = posterior))
# Clear variables and console
rm(list = ls())
cat("\014")
# Load packages
library(tidyverse)
library(janitor)
library(rstan)
library(bayesplot)
# 6.13 ============
# STEP 1: DEFINE the model
bb_model <- "
data {
int<lower = 0, upper = 10> Y;
}
parameters {
real<lower = 0, upper = 1> pi;
}
model {
Y ~ binomial(10, pi);
pi ~ beta(3, 8);
}
"
# (a) STEP 2: SIMULATE the posterior
bb_sim <- stan(model_code = bb_model, data = list(Y = 2),
chains = 3, iter = 6000*2, seed = 123456)
load("sim_cv05_pr04.RData")
load("sim_cv05_pr04.RData")
setwd("~/Bayes/Cviceni 05")
load("sim_cv05_pr04.RData")
View(bb_sim)
# (b)
mcmc_trace(bb_sim, pars = "pi", size = 0.1)
# (d)
# Histogram of the Markov chain values
mcmc_hist(bb_sim, pars = "pi") +
yaxis_text(TRUE) +
ylab("count")
# Density plot of the Markov chain values
mcmc_dens(bb_sim, pars = "pi") +
yaxis_text(TRUE) +
ylab("density")
# Density plots of individual chains
mcmc_dens_overlay(bb_sim, pars = "pi") +
ylab("density")
# Calculate the effective sample size ratio
neff_ratio(bb_sim, pars = c("pi"))
# autocorrelation
mcmc_acf(bb_sim, pars = "pi")
# R-hat
rhat(bb_sim, pars = "pi")
# Clear variables and console
rm(list = ls())
cat("\014")
# Load packages
library(tidyverse)
library(janitor)
library(rstan)
library(bayesplot)
# (a)
# Step 1: Define a grid of lambda values
grid_data  <- data.frame(
lambda_grid = seq(from = 0, to = 1, length = 501))
View(grid_data)
# Clear variables and console
rm(list = ls())
# (a)
# Step 1: Define a grid of pi values
grid_data  <- data.frame(
pi_grid = seq(from = 0, to = 1, length = 501))
# (a)
# Step 1: Define a grid of pie values
grid_data  <- data.frame(
pie_grid = seq(from = 0, to = 1, length = 501))
# (a)
# Step 1: Define a grid of pie values
grid_data  <- data.frame(
pie_grid = seq(from = 0, to = 1, length = 501))
# Step 2: Evaluate the prior & likelihood at each lambda
# 2.a My prior function
my_prior <- function(x, mu, sigma) { # v akej hodnote, aka stredna hodnota, aky rozptyl
f_x <- dnorm(x, mean = mu, sd = sigma)
f_x
}
my_prior(0.25, 0.5, 0.1)
# mozeme dat aj tu obmedzenie, ze x ma zmysel len od 0 do 1, inak je to nastavene aj v mriezke, lebo ine hodnoty tam nie su
# cize predefinujme
my_prior <- function(x, mu, sigma) { # v akej hodnote, aka stredna hodnota, aky rozptyl
if (x < 0 || x > 1 ) return (0)
dnorm(x, mean = mu, sd = sigma)
}
my_prior(0.25, 0.5, 0.1)
my_prior(-0.25, 0.5, 0.1)
# ale obsah pod hustotou nie je jedna, treba to normalizovat
# cize este predefinujme
my_prior <- function(x, mu, sigma) { # v akej hodnote, aka stredna hodnota, aky rozptyl
if (x < 0 || x > 1 ) return (0)
# odseknute casti pod 0 a nad 1 - tato cast chyba do obsahu 1 potom
p_low  <- pnorm(0, mean = mu, sd = sigma, lower.tail = TRUE)
p_upper  <- pnorm(0, mean = mu, sd = sigma, lower.tail = TRUE)
# normalizujeme, t.j. prenasobit 1/obsah bez odseknutych casti
dnorm(x, mean = mu, sd = sigma)*1/(1-p_low-p_upper)
}
dbinom(x = y, size = n, prob = pie)
